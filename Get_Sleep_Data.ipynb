{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62a88ab",
   "metadata": {},
   "source": [
    "### Importing the Packages \n",
    "\n",
    "If you don't have the mne package, run in your terminal \"pip install mne\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24e5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import mne\n",
    "import requests \n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e617de80",
   "metadata": {},
   "source": [
    "## Getting the Data\n",
    "\n",
    "The code below is provided from the developer that whom conducted the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a34b2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "def download_url(url, save_path, chunk_size = 128):\n",
    "    r = requests.get(url, stream = True)\n",
    "    \n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in tqdm(r.iter_content(chunk_size=chunk_size),\n",
    "                          desc = f'downloading {save_path.split(\"/\")[-1]} ...'):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ecc09",
   "metadata": {},
   "source": [
    "**Note the following:**\n",
    "\n",
    "- Line 3 is the location the csv file 'available_subjects.csv'\n",
    "- Line 5 is the desired location the .egg, .vmrk, .vhrk files will be downloaded, if the folder doesn't existed the folder will be made\n",
    "- Line 18 is a conditional statement to no repeat downloads, comment it out once, then add it back after. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # download the data if not\n",
    "    dataframe_dir   = '../Nap EEG/data'\n",
    "    df              = pd.read_csv(os.path.join(dataframe_dir,'available_subjects.csv'))\n",
    "    EEG_dir         = '../Nap EEG/data' #download location\n",
    "    annotation_dir  = '../annotations'\n",
    "    for f in [EEG_dir,annotation_dir]:\n",
    "        if not os.path.exists(f):\n",
    "            os.mkdir(f)\n",
    "    \n",
    "    for (sub,day),row in df.groupby(['sub','day']):\n",
    "        \n",
    "        url_eeg         = row['link'].values[0] #list with the len \n",
    "        url_vmrk        = row['link'].values[1]\n",
    "        url_vhdr        = row['link'].values[2]\n",
    "        url_annotation  = row['annotation_file_link'].values[0]\n",
    "        \n",
    "        if len(os.path.join(EEG_dir)) < 1: #remove this if statement to download that data once\n",
    "    \n",
    "            for url in [url_eeg,url_vmrk,url_vhdr]: #nested for loop\n",
    "                    download_url(url,\n",
    "                                 os.path.join(EEG_dir,url.split('/')[-1],))\n",
    "\n",
    "            download_url(url_annotation,\n",
    "                         os.path.join(annotation_dir,\n",
    "                                      f'suj{sub}_day{day}_annotations.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
